{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing des données de TME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import des librairies **Numpy**, **Matplotlib** et **Pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set_style('ticks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import des données **pdv** sur les points de ventes, **titres_best** sur les titres en vente, **ventes_process** sur les transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pdv = pd.read_csv('CSV/pdv.csv',\n",
    "                     sep=',',decimal=',',error_bad_lines=False,\n",
    "                     index_col=0,dtype='unicode')\n",
    "df_titres = pd.read_csv(\"CSV/titres_best.csv\",\n",
    "                        sep=',',error_bad_lines=False,index_col=0,\n",
    "                        dtype='unicode')\n",
    "df_ventes = pd.read_csv(\"CSV/ventes_process.csv\",\n",
    "                        sep=',',error_bad_lines=False,index_col=0,\n",
    "                        dtype='unicode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Traitement de pdv.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noms des colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pdv.columns=[\"numero_pdv\",\"departement\",\"lineaire_sol\",\n",
    "                \"lineaire_developpe\",\"region\",\"code_postal\",\"localite\",\n",
    "                \"lundi_ouv_am\",\"lundi_ferm_am\",\"lundi_ouv_pm\",\"lundi_ferm_pm\",\n",
    "                \"mardi_ouv_am\",\"mardi_ferm_am\",\"mardi_ouv_pm\",\"mardi_ferm_pm\",\n",
    "                \"mercredi_ouv_am\",\"mercredi_ferm_am\",\"mercredi_ouv_pm\",\"mercredi_ferm_pm\",\n",
    "                \"jeudi_ouv_am\",\"jeudi_ferm_am\",\"jeudi_ouv_pm\",\"jeudi_ferm_pm\",\n",
    "                \"vendredi_ouv_am\",\"vendredi_ferm_am\",\"vendredi_ouv_pm\",\"vendredi_ferm_pm\",\n",
    "                \"samedi_ouv_am\",\"samedi_ferm_am\",\"samedi_ouv_pm\",\"samedi_ferm_pm\",\n",
    "                \"dimanche_ouv_am\",\"dimanche_ferm_am\",\"dimanche_ouv_pm\",\"dimanche_ferm_pm\",\n",
    "                \"jourferie_ouv_am\",\"jourferie_ferm_am\",\"jourferie_ouv_pm\",\"jourferie_ferm_pm\",\n",
    "                \"activite_alimentation\",\"activite_none\",\"activite_bar_cafe\",\n",
    "                \"activite_bazar_bricolage\",\"activite_cadeaux_jouets\",\n",
    "                \"activite_carterie\",\"activite_confiserie\",\n",
    "                \"activite_francaisedesjeux\",\"activite_hotel_camping\",\n",
    "                \"activite_librairie\",\"activite_libreservice\",\"activite_loto\",\n",
    "                \"activite_pmu\",\"activite_papeterie\",\"activite_photo_video\",\n",
    "                \"activite_relaiscolis\",\"activite_souvenir\",\"activite_stationservice\",\n",
    "                \"activite_tabac\",\"env_administration_publique\",\n",
    "                \"env_arret_transport_commun\",\"env_autoroute\",\"env_campagne_rural\",\n",
    "                \"env_centrecommercial\",\"env_commerce_centreville\",\n",
    "                \"env_commerce_peripherie\",\"env_ecole_primaire\",\"env_ecole_secondaire_sup\",\n",
    "                \"env_gare_metro\",\"env_hopital\",\"env_hotel_camping\",\"env_immeubles\",\n",
    "                \"env_lieu_culte\",\"env_lieu_sportif\",\"env_lieu_touristique\",\n",
    "                \"env_route_nationale_departementale\",\"env_station_balnéaire\",\n",
    "                \"env_station_ski\",\"env_ZAC_ZI_ZAE\",\"env_zone_pavillonnaire\",\n",
    "                \"ouverture_samedi\",\"ouverture_dimanche\",\"ouverture_jourferie\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numéros de point de vente\n",
    "- nump_pdv est encodé en string et il existe des num_pdv ayant des espaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24736, 82)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pdv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb de point de vente contenant des espaces : 34\n",
      "Les lignes correspondantes seront retirées du dataframe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(24702, 82)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_if_to_delete_num(x) :\n",
    "    if ' ' in x :\n",
    "        return True\n",
    "    if 'Inco' in x :\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "nb_pdv_espace = df_pdv.numero_pdv.apply(test_if_to_delete_num).sum()\n",
    "\n",
    "print(\"Nb de point de vente contenant des espaces :\", nb_pdv_espace)\n",
    "print(\"Les lignes correspondantes seront retirées du dataframe\")\n",
    "df_pdv = df_pdv[~df_pdv.numero_pdv.apply(test_if_to_delete_num)]\n",
    "df_pdv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convertir en int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pdv['numero_pdv'] = df_pdv['numero_pdv'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1884 pdv correspondent à des doublons\n",
      "On réfléchira plus tard à comment les gérer\n"
     ]
    }
   ],
   "source": [
    "print(df_pdv[df_pdv.numero_pdv.duplicated()].shape[0], 'pdv correspondent à des doublons')\n",
    "print(\"On réfléchira plus tard à comment les gérer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Localisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pdv.localite.isna().sum()\n",
    "#df_pdv.region.isna().sum()\n",
    "#df_pdv.departement.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = [\"departement\", \"region\", \"localite\"]\n",
    "\n",
    "for col in strings:\n",
    "    df_pdv[col] = df_pdv[col].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linéaire au sol et linéaire developpé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pdv[\"lineaire_sol\"] = df_pdv[\"lineaire_sol\"].str.replace(',','.').astype(float)\n",
    "df_pdv[\"lineaire_developpe\"] = df_pdv[\"lineaire_developpe\"].str.replace(',','.').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb lineare_sol NULL : 15\n",
      "nb lineare_sol ZEROS : 653\n",
      "nb lineaire_developpe ZEROS : 692\n"
     ]
    }
   ],
   "source": [
    "print('nb lineare_sol NULL :', df_pdv.lineaire_sol.isnull().sum())\n",
    "print('nb lineare_sol ZEROS :', (df_pdv.lineaire_sol == 0.0).sum())\n",
    "print('nb lineaire_developpe ZEROS :', (df_pdv.lineaire_developpe == 0.0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Les valeurs NULL et nulles seront remplacées par la moyenne par département."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numero_pdv</th>\n",
       "      <th>departement</th>\n",
       "      <th>lineaire_sol</th>\n",
       "      <th>lineaire_developpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>42279</td>\n",
       "      <td>03 - ALLIER</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>87696</td>\n",
       "      <td>03 - ALLIER</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>83387</td>\n",
       "      <td>06 - ALPES MARITIMES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>9065</td>\n",
       "      <td>09 - ARIEGE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>34852</td>\n",
       "      <td>11 - AUDE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      numero_pdv           departement  lineaire_sol  lineaire_developpe\n",
       "495        42279           03 - ALLIER           0.0                 5.6\n",
       "669        87696           03 - ALLIER           0.0                 0.0\n",
       "1171       83387  06 - ALPES MARITIMES           0.0                 0.0\n",
       "1549        9065           09 - ARIEGE           0.0                20.0\n",
       "1851       34852             11 - AUDE           0.0                 0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = df_pdv[(df_pdv.lineaire_sol.isnull() | df_pdv.lineaire_sol == 0.0)][['numero_pdv', 'departement','lineaire_sol', 'lineaire_developpe']]\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for depart in df_pdv.departement.unique():\n",
    "    condition_sol = ((df_pdv.departement == depart) &\\\n",
    "                    (df_pdv.lineaire_sol.isnull() | df_pdv.lineaire_sol == 0.0))\n",
    "    condition_dev = (df_pdv.departement == depart) &\\\n",
    "                    (df_pdv.lineaire_developpe.isnull() | df_pdv.lineaire_developpe == 0.0)\n",
    "    df_pdv.loc[condition_sol, 'lineaire_sol'] = np.nan\n",
    "    df_pdv.loc[condition_dev, 'lineaire_developpe'] = np.nan\n",
    "    \n",
    "    moyenne_par_dep = df_pdv.loc[df_pdv.departement == depart].lineaire_sol.mean()\n",
    "    nb_etag_moyen = (df_pdv[df_pdv.departement == depart].lineaire_developpe/\\\n",
    "                     df_pdv[df_pdv.departement == depart].lineaire_sol).mean()   \n",
    "    \n",
    "    df_pdv.loc[condition_sol, 'lineaire_sol'] = moyenne_par_dep\n",
    "    df_pdv.loc[condition_dev, 'lineaire_developpe'] = nb_etag_moyen * df_pdv.loc[condition_sol, 'lineaire_sol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numero_pdv</th>\n",
       "      <th>departement</th>\n",
       "      <th>lineaire_sol</th>\n",
       "      <th>lineaire_developpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>42279</td>\n",
       "      <td>03 - ALLIER</td>\n",
       "      <td>7.899167</td>\n",
       "      <td>5.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>87696</td>\n",
       "      <td>03 - ALLIER</td>\n",
       "      <td>7.899167</td>\n",
       "      <td>72.549980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>83387</td>\n",
       "      <td>06 - ALPES MARITIMES</td>\n",
       "      <td>9.918065</td>\n",
       "      <td>92.078453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>9065</td>\n",
       "      <td>09 - ARIEGE</td>\n",
       "      <td>9.007229</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>34852</td>\n",
       "      <td>11 - AUDE</td>\n",
       "      <td>8.788884</td>\n",
       "      <td>80.325417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      numero_pdv           departement  lineaire_sol  lineaire_developpe\n",
       "495        42279           03 - ALLIER      7.899167            5.600000\n",
       "669        87696           03 - ALLIER      7.899167           72.549980\n",
       "1171       83387  06 - ALPES MARITIMES      9.918065           92.078453\n",
       "1549        9065           09 - ARIEGE      9.007229           20.000000\n",
       "1851       34852             11 - AUDE      8.788884           80.325417"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pdv[['numero_pdv', 'departement', 'lineaire_sol', 'lineaire_developpe']].loc[tmp.index[:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code postal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Codes nuls ou inconnus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 codes postaux sont inconnus\n",
      "Les lignes associées seront supprimées\n"
     ]
    }
   ],
   "source": [
    "print(df_pdv.code_postal.apply(test_if_to_delete_num).sum(), \"codes postaux sont inconnus\")\n",
    "print(\"Les lignes associées seront supprimées\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24697, 82)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pdv = df_pdv[~df_pdv.code_postal.apply(test_if_to_delete_num)]\n",
    "df_pdv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Codes incorrects : on ajoute un 0 devant ceux à 4 chiffres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pdv['len_cp_tmp'] = df_pdv['code_postal'].map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    22990\n",
       "4     1707\n",
       "Name: len_cp_tmp, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pdv['len_cp_tmp'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_cp(x):\n",
    "    if len(x)==4:\n",
    "        return '0'+x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pdv['code_postal'] = df_pdv['code_postal'].apply(correct_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pdv.drop(['len_cp_tmp'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activités et environnements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df_pdv.columns if 'env' in col or 'acti' in col]\n",
    "\n",
    "for col in cols:\n",
    "    df_pdv[col] = df_pdv[col].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pdv[cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1118 lignes ont aucune données ni pour activité ni pour environnement.\n",
      "Une nouvelle variable booléenne acti_env_inconnu va être créée.\n"
     ]
    }
   ],
   "source": [
    "print(df_pdv[cols].isnull().sum().iloc[0], \"lignes ont aucune données ni pour activité ni pour environnement.\")\n",
    "print(\"Une nouvelle variable booléenne acti_env_inconnu va être créée.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pdv['activite_env_connu'] = df_pdv.activite_alimentation.notnull().astype(int)\n",
    "#tous ceux avec pas de valeurs pour act ou env sont mis à 0\n",
    "for col in cols :\n",
    "    df_pdv.loc[df_pdv[col].isnull(), col] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in cols :\n",
    "    #print(df_pdv[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pdv['activite_env_connu']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horaires d'ouverture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Créer une colonne pour chq jour pour dire si oui ou non c'est ouvert ce jour-là"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "jours = ['lundi', 'mardi', 'mercredi', 'jeudi', 'vendredi', 'samedi', 'dimanche', 'jourferie']\n",
    "ouvertures = ['_ouv_am', '_ferm_am', '_ouv_pm', '_ferm_pm']\n",
    "cols_jours_brut = list(itertools.product(jours, ouvertures))\n",
    "cols_jours = [col[0] + col[1] for col in cols_jours_brut]\n",
    "for col in cols_jours :\n",
    "    df_pdv[col] = df_pdv[col].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def is_open(x, jour):\n",
    "    for o in ouvertures :\n",
    "        if x[jour+o] is not pd.NaT :\n",
    "            if x[jour+o].time() != datetime.time(0, 0) :\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jour in jours: \n",
    "    df_pdv[jour + \"_is_open\"] = df_pdv.apply(lambda x : is_open(x, jour), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemple\n",
    "jour = 'lundi'\n",
    "x = df_pdv.loc[172]\n",
    "o = '_ouv_am'\n",
    "#print(x['lundi_ouv_am'].time())\n",
    "is_open(x, jour)\n",
    "#x[jour+o].time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_pdv.loc[172] \n",
    "#x.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_time(x):\n",
    "    if x is not pd.NaT:\n",
    "        return x.time()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols_jours:\n",
    "    df_pdv[col + \"_in_time\"]= df_pdv[col].apply(convert_to_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b) Traiter les ouvertures à 00h01, 1h et 3h du mat (insignifiantes) et mettre en False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouvertures_am = ['_ouv_am']\n",
    "cols_am = [col[0] + col[1] for col in list(itertools.product(jours, ouvertures_am))]\n",
    "cols_am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols_am:\n",
    "    df_pdv.loc[df_pdv[col+ \"_in_time\"] < datetime.time(2, 0),col[:-7]+ \"_is_open\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO horaires incohérents (fermeture avant ouverture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c) Si c'est fermé (False) tous les jours, c'est qu'on a pas les données (pour éviter de tout fausser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouvertures_jours = [jour + \"_is_open\" for jour in jours]\n",
    "def is_true_data(x):\n",
    "    for col in ouvertures_jours:\n",
    "        if x[col]==True:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pdv[\"horaires_dispo\"] = df_pdv.apply(lambda x : is_true_data(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pdv[\"horaires_dispo\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### d) Si le pdv ouvre un jour, calculer nombres d'heures d'ouverture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "\n",
    "def compute_opening_hours(jour, x):\n",
    "    nombre_secondes = 0\n",
    "    if x[jour + \"_is_open\"]==True:\n",
    "        #si valeurs identiques au milieu (null, 0 ou autre) : pas de changement réel\n",
    "        if ((x[jour + \"_ferm_am\"]==x[jour + \"_ouv_pm\"]) | ((x[jour + \"_ferm_am\"] is pd.NaT) & (x[jour + \"_ferm_am\"] is pd.NaT))):\n",
    "            if (x[jour + \"_ferm_pm\"] is not pd.NaT):\n",
    "                if (x[jour + \"_ouv_am\"] is not pd.NaT):\n",
    "                    nombre_secondes = x[jour + \"_ferm_pm\"] - x[jour + \"_ouv_am\"]\n",
    "        else:\n",
    "            if (x[jour + \"_ouv_am\"] is not pd.NaT):\n",
    "                    if (x[jour + \"_ouv_pm\"] is not pd.NaT):\n",
    "                         if (x[jour + \"_ferm_am\"] is not pd.NaT):\n",
    "                                 if (x[jour + \"_ferm_pm\"] is not pd.NaT):\n",
    "                                        nombre_secondes = x[jour + \"_ferm_pm\"]-x[jour + \"_ouv_pm\"] + x[jour + \"_ferm_am\"]-x[jour + \"_ouv_am\"]\n",
    "    #en forme de time_delta pas besoin de conversion\n",
    "    return nombre_secondes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jour in jours: \n",
    "    df_pdv[jour + \"_total_hours\"] = df_pdv.apply(lambda x : compute_opening_hours(jour,x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = df_pdv.loc[1]\n",
    "#y = df_pdv.loc[172]\n",
    "y = df_pdv.loc[22949]\n",
    "#y.tail(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A retenir : \n",
    "- Colonne qui indique si on a les données d'ouvertures : **horaires_dispo** : T/F\n",
    "- Colonnes pour savoir si c'est ouvert chaque jour : comme **mardi_is_open** : T/F\n",
    "- Colonnes pour connaitre le nombre d'heures d'ouvertures par jour : comme **mardi_total_hours** : un nombre ou 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Traitement de titres.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_(x):\n",
    "    try : \n",
    "        return float(x)\n",
    "    except :\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noms des colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titres.columns=[\"distributeur\",\"titre\",\"numero_parution\",\"date_MEV\",\n",
    "                   \"prix_vente\",\"plus_produit\",\"type\",\"cout_magazine\",\n",
    "                   \"cout_plus_produit\",\"cout_conditionnement\",\n",
    "                   \"contrainte_production\",\"prevision_vente\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titres[\"prevision_vente\"]=df_titres[\"prevision_vente\"].astype(float)\n",
    "df_titres[\"contrainte_production\"]=df_titres[\"contrainte_production\"].astype(float)\n",
    "df_titres[\"prix_vente\"]=df_titres[\"prix_vente\"].astype(float)\n",
    "df_titres[\"plus_produit\"]=df_titres[\"plus_produit\"].astype(int)\n",
    "df_titres[\"cout_plus_produit\"]=df_titres[\"cout_plus_produit\"].apply(replace_)\n",
    "df_titres[\"cout_conditionnement\"]=df_titres[\"cout_conditionnement\"].astype(float)\n",
    "df_titres[\"cout_magazine\"]=df_titres[\"cout_magazine\"].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dates de mise en vente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modification des dates de la forme \"mercredi 12 janvier 2019\" et \"2019-01-12 00:00:00\" en 2019-01-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mois = {\n",
    "    \"janvier\":\"01\",\n",
    "    \"février\":\"02\",\n",
    "    \"mars\":\"03\",\n",
    "    \"avril\":\"04\",\n",
    "    \"mai\":\"05\",\n",
    "    \"juin\":\"06\",\n",
    "    \"juillet\":\"07\",\n",
    "    \"août\":\"08\",\n",
    "    \"septembre\":\"09\",\n",
    "    \"octobre\":\"10\",\n",
    "    \"novembre\":\"11\",\n",
    "    \"décembre\":\"12\"  \n",
    "}\n",
    "\n",
    "def preprocessing_date(liste, column_name):\n",
    "    res=[]\n",
    "    for date in liste[column_name]:\n",
    "        # Split la date pour faciliter son traitement\n",
    "        date_split=date.split(\" \")\n",
    "        if date[0:2]!=\"20\": #type [[mercredi],[12],[janvier],[2019]]\n",
    "            if len(date_split[1])!= 2:\n",
    "                date_split[1]='0'+date_split[1]\n",
    "            date_corrige=date_split[3]+'-'+mois[date_split[2]]+'-'+date_split[1]\n",
    "            res.append(date_corrige)\n",
    "        else : #type [[2019-01-12],[00:00:00]]\n",
    "            res.append(date_split[0])\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titres[\"date_MEV\"]=preprocessing_date(df_titres,\"date_MEV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titres.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement des prix \n",
    "- Pour ne garder que 2 décimales au maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_prix(liste, column_name):\n",
    "    res=[]\n",
    "    for price in liste[column_name]:\n",
    "       res.append(round(price,2))\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titres[\"prix_vente\"]=preprocessing_prix(df_titres,\"prix_vente\")\n",
    "df_titres[\"cout_magazine\"]=preprocessing_prix(df_titres,\"cout_magazine\")\n",
    "df_titres[\"cout_plus_produit\"]=preprocessing_prix(df_titres,\"cout_plus_produit\")\n",
    "df_titres[\"cout_conditionnement\"]=preprocessing_prix(df_titres,\"cout_conditionnement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Traitement de ventes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventes.columns=[\"titre\",\"paru\",\"pdv\",\"fournis\",\"ventes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventes[\"Fournis\"]=df_ventes[\"Fournis\"].astype(float)\n",
    "df_ventes[\"Ventes\"]=df_ventes[\"Ventes\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Export des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nom du dossier où on veut les stocker\n",
    "path = 'CSV-Clean'\n",
    "\n",
    "df_pdv.to_csv(path + \"/pdv_processed.csv\")\n",
    "#df_titres.to_csv(path + \"/titres_processed.csv\")\n",
    "#df_ventes.to_csv(path + \"/ventes_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
